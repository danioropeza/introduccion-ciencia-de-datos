{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "__[Web Scraping](https://www.imperva.com/learn/application-security/web-scraping-attack/)__ es el proceso de utilizar bots para extraer contenido y datos de un sitio web. En este proceso, se extrae el código HTML y los datos almacenados en una base de datos. Web Scraping permite replicar el contenido completo de un sitio web en cualquier lugar. Muchos negocios digitales que dependen de la recolección de datos, utilizan este proceso.\n",
    "\n",
    "A continuación, se mencionan algunos de los casos aplicables de esta técnica:\n",
    "- Clasificación de contenido, a tráves de la extracción de datos de multiples sitios web.\n",
    "- Comparación de precios y descripciones de productos sobre la base de sitios web que ofrecen productos.\n",
    "- Análisis de sentimiento a tráves de la extracción de datos de foros y redes sociales.\n",
    "\n",
    "Web Scraping es también utilizado para propósitos ilegales como ser: la subvaloración de precios y el robo de contenido protegido por derechos de autor. Esto podría provocar pérdidas financieras, especialmente si es una empresa que depende fuertemente de modelos de precios competitivos u ofertas en la distribución de contenido. Normalmente, las páginas tiene un archivo robots.txt en el cual especifican si es permitido o no extraer datos de ellas.\n",
    "\n",
    "__Nota__: evita realizar este proceso si previamente no cuentas con autorización del autor.\n",
    "\n",
    "Si quieres saber más, te dejamos abajo unos enlaces que podrían interesarte.\n",
    "\n",
    "\n",
    "- __[Estándar de exclusión de robots](https://es.wikipedia.org/wiki/Est%C3%A1ndar_de_exclusi%C3%B3n_de_robots)__\n",
    "\n",
    "- __[5 Things You Need to Know Before Scraping Data From Facebook](https://www.octoparse.com/blog/5-things-you-need-to-know-before-scraping-data-from-facebook)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Extraer el código HTML](#1)\n",
    "2. [Realizar búsquedas](#2)\n",
    "3. [Experimentar estrategias para extraer datos](#3)\n",
    "4. [Crear funciones y procesar los elementos](#4)\n",
    "5. [Almacenar los datos en archivos](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Extraer el código HTML\n",
    "\n",
    "Para explicar el proceso de Web Scraping, analizaremos la página web [Auto MPG web page](http://localhost:8000/auto_mpg.html). Esa página web es una página que fue creada para este tutorial. Recolecta los datos open source del dataset [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg). Puedes crear un pequeño servidor que retorne página [Auto MPG web page](http://localhost:8000/auto_mpg.html). Puedes cambiar el puerto si es diferente al 8000.\n",
    "\n",
    "Las columnas del dataset son las siguientes: nombre, cilindros, peso, año, territorio, aceleración, millas por galón, caballos de potencia y desplazamiento.\n",
    "\n",
    "Ejecuta la siguientes líneas de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL './html/auto_mpg.html': No schema supplied. Perhaps you meant http://./html/auto_mpg.html?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qh/pvjjyjr96l329fgsgrwn11nr0000gp/T/ipykernel_13494/2358134178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrespuesta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./html/auto_mpg.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         p.prepare(\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL './html/auto_mpg.html': No schema supplied. Perhaps you meant http://./html/auto_mpg.html?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "respuesta = requests.get(\"./html/auto_mpg.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca BeautifulSoup de bs4 nos permitirá análizar documentos HTML. \n",
    "\n",
    "Ejecuta las siguientes líneas de código para utilizar esta librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "pagina = BeautifulSoup(respuesta.text, \"html.parser\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualiza si extrajiste bien el código HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pagina.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes acceder directamente al body del html utilizando pagina.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pagina.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## Realizar búsquedas\n",
    "Puedes utilizar la función .find y .find_all para encontrar los elementos que deseas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pagina.body.find(name=\"div\", attrs={\"id\":\"car-1\"}))\n",
    "print(len(pagina.body.find_all(name=\"div\", attrs={\"class\":\"car_block\"})))\n",
    "print(pagina.body.find_all(name=\"div\", attrs={\"class\":\"car_block\"})[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes acceder a los atributos de cada elemento como en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_divs = pagina.body.find_all(name=\"div\", attrs={\"class\":\"car_block\"})\n",
    "div = car_divs[0]\n",
    "div['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## Experimentar estrategias para extraer datos\n",
    "Si deseas extraer únicamente el contenido sin elementos HTML, realiza lo siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chevrolet Chevelle Malibu (1970, USA)  Achieves 18.0 mpg with 8 cylinders backed by 130 hp, 307.0 cubic inches of displacement, weighing 3,504 lbs with 0-60 mph acceleration in 12.0 seconds\n"
     ]
    }
   ],
   "source": [
    "print(div.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes crear un generador (similar a un iterable) de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(div.stripped_strings)\n",
    "print(list(div.stripped_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes utilizar funciones poprias del lenguaje para obtener un mejor resultado de los datos que deseas obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.find(\"span\", attrs={\"class\":\"mpg\"}).text\n",
    "div.find(\"span\", attrs={\"class\":\"mpg\"}).text.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluso puedes utilizar expresiones regulares si así lo deseas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(r'.* (\\d+.\\d+) cubic inches', div.text)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## Crear funciones y procesar los elementos\n",
    "Finalmente, te recomendamos crear funciones para cada item y procesar los elementos que contienen los datos.\n",
    "\n",
    "A continuación se muestra un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extraer_desplazamiento(div_automovil_text):\n",
    "    texto_de_desplazamiento = re.findall(r'.* (\\d+.\\d+) cubic inches', div_automovil_text)[0]\n",
    "    return float(texto_de_desplazamiento)\n",
    "\n",
    "def extraer_caballos_potencia(div_automovil):\n",
    "    texto_caballo_potencia = div_automovil.find('span', class_='horsepower').text\n",
    "    try:\n",
    "        texto_caballo_potencia = float(texto_caballo_potencia)\n",
    "    except ValueError:\n",
    "        texto_caballo_potencia = \"NULL\"\n",
    "    return texto_caballo_potencia\n",
    "\n",
    "def extraer_mpg(div_automovil):\n",
    "    texto_de_mpg = div_automovil.find(\"span\", attrs={\"class\":\"mpg\"}).text\n",
    "    try:\n",
    "        mpg = float(texto_de_mpg.split(' ')[0])\n",
    "    except ValueError:\n",
    "        mpg = \"NULL\"\n",
    "    return mpg\n",
    "\n",
    "def extraer_aceleracion(div_automovil):\n",
    "    return float(div_automovil.find('span', class_='acceleration').text)\n",
    "\n",
    "def extraer_territorio_y_anio(div_automovil):\n",
    "    texto_de_from = div_automovil.find(\"span\", attrs={\"class\":\"from\"}).text\n",
    "    anio, territorio = texto_de_from.strip('()').split(',')\n",
    "    anio = int(anio.strip())\n",
    "    territorio = territorio.strip()\n",
    "    return territorio, anio\n",
    "\n",
    "def extraer_peso(div_automovil):\n",
    "    texto_de_peso = div_automovil.find('span', class_='weight').text\n",
    "    return int(texto_de_peso.replace(',', ''))\n",
    "\n",
    "def extraer_cilindros(div_automovil):\n",
    "    return int(div_automovil.find('span', class_='cylinders').text)\n",
    "\n",
    "def extraer_nombre(div_automovil):\n",
    "    return div_automovil.find('span', class_='car_name').text\n",
    "\n",
    "def extraer_datos(div_automovil):\n",
    "    fila = {}\n",
    "    fila[\"nombre\"] = extraer_nombre(div_automovil)\n",
    "    fila[\"cilindros\"] = extraer_cilindros(div_automovil)\n",
    "    fila[\"peso\"] = extraer_peso(div_automovil)\n",
    "    fila[\"territorio\"], fila[\"anio\"] = extraer_territorio_y_anio(div_automovil)\n",
    "    fila[\"aceleracion\"] = extraer_aceleracion(div_automovil)\n",
    "    fila[\"mpg\"] = extraer_mpg(div_automovil)\n",
    "    fila[\"caballos_potencia\"] = extraer_caballos_potencia(div_automovil)\n",
    "    fila[\"desplazamiento\"] = extraer_desplazamiento(div_automovil.text)\n",
    "    return fila\n",
    "\n",
    "def extraer_datos_automoviles(pagina):\n",
    "    divs_automoviles = pagina.body.find_all(name=\"div\", attrs={\"class\":\"car_block\"})\n",
    "    return list(map(extraer_datos, divs_automoviles))\n",
    "\n",
    "        \n",
    "respuesta = requests.get(\"http://localhost:8000/auto_mpg.html\")\n",
    "pagina = BeautifulSoup(respuesta.text, \"html.parser\" )\n",
    "datos_automoviles = extraer_datos_automoviles(pagina)\n",
    "\n",
    "print(f\"Se ha extraido {len(datos_automoviles)} filas\")\n",
    "print(datos_automoviles[1])\n",
    "print(datos_automoviles[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## Almacenar los datos en archivos\n",
    "Puedes almacenar los datos extraídos en un archivo de tu preferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def almacenar_datos_en_un_archivo_csv(datos_automoviles):\n",
    "    with open(\"datos_automoviles1.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=datos_automoviles[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(datos_automoviles)\n",
    "almacenar_datos_en_un_archivo_csv(datos_automoviles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
