{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Habilitar intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Lenguaje Natural (NLP)\n",
    "__[Definición](https://es.wikipedia.org/wiki/Procesamiento_de_lenguajes_naturales)__\n",
    "\n",
    "Hacer que la computadora pueden entender y responder en lenguage natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas aplicaciones\n",
    "\n",
    "### Extracción de palabras clave (Keyword extraction)\n",
    "Identificación automática de términos que mejor describan el tema de un documento\n",
    "\n",
    "### Extracción de entidades (Named-Entity Recognition)\n",
    "Busca localizar en el texto entidades como personas, organizaciones, lugares, expresiones de tiempo y cantidades.\n",
    "\n",
    "### Clasificación de texto\n",
    "Asignar una categoría a un documento:\n",
    "\n",
    "- Detección de Spam\n",
    "- Sentiment Analysis\n",
    "- Priorización de contenido (mails, sistema de alearta temprana)\n",
    "\n",
    "### Resumen automático (Text summarization)\n",
    "Encontrar las oraciones más informativas en un documento.\n",
    "\n",
    "### Topic modeling\n",
    "¿Cuál es el tema de un (conjunto) de documento(s)?\n",
    "\n",
    "### Traducción automática (Machine translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas/Problemas \n",
    "### Tokenización\n",
    "Dividir el texto en palabras u oraciones. Necesario como primer paso para obtener una representación del texto con la cual se puede realizar el procesamiento.\n",
    "\n",
    "![Tokenización](01_tokenization.png)\n",
    "\n",
    "### Eliminar palabras de parada (stopwords)\n",
    "Eliminar palabras que no le agregan significado al texto (artículos, conjunciones, preposiciones, etc). Necesario cuando se requiera reducir el vocabulario del problema y evitar al mismo tiempo perder la menor cantidad de información posible.\n",
    "\n",
    "![Tokenización](02_remove_stopwords.png)\n",
    "\n",
    "**Referencias**\n",
    "\n",
    "__[Cómo eliminar las palabras de parada usando nltk o python](https://www.pythond.com/21143/como-eliminar-las-palabras-de-parada-usando-nltk-o-python.html)__\n",
    "\n",
    "__[Proyecto stop-words](https://pypi.org/project/stop-words/)__\n",
    "\n",
    "__[Proyecto node-nltk-stopwords](https://github.com/xiamx/node-nltk-stopwords/blob/master/data/stopwords/spanish)__\n",
    "\n",
    "__[Stopwords @ ranks.nl](https://www.ranks.nl/stopwords)__\n",
    "\n",
    "###  Lematización **\n",
    "Eliminar las variaciones de la misma palabra para tratar las variaciones como una sola entidad. (close, closed, closing; caminaba, caminando, caminar). Al igual que la eliminación de palabras de parada, se emplea para reducir la cantidad de elementos en el vocabulario de un problema.\n",
    "\n",
    "**Referencias**\n",
    "\n",
    "__[Lematización](https://es.wikipedia.org/wiki/Lematizaci%C3%B3n)__\n",
    "\n",
    "__[Stemmer-es, Un lematizador de español](http://stemmer-es.sourceforge.net/)__\n",
    "\n",
    "\n",
    "### Identificar n-gramas\n",
    "Grupos de N palabras que están siempre juntas (Nueva York, Santa Cruz) y que deben tratarse como una sola entidad/palabra.\n",
    "\n",
    "**Referencias**\n",
    "\n",
    "__[Modelo bolsa de palabras](https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras)__\n",
    "\n",
    "__[N-grama](https://es.wikipedia.org/wiki/N-grama)__\n",
    "\n",
    "### Desambiguación lingüística (Word Sense Disambiguation)**\n",
    "Asignar significado en base al contexto. Con qué sentido se usa una palabra? En el caso de la __[polisemia](https://es.wikipedia.org/wiki/Polisemia)__, cuál de los significados es el más apropiado dado el contexto?\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "- Placeres de la carne.\n",
    "- La carne está sabrosa.\n",
    "\n",
    "\n",
    "- Puso dos velas a San Pedro.\n",
    "- Los egipcios fueron los primeros constructores de barcos de vela de los que se tiene noticia.\n",
    "\n",
    "El desarrollo de algoritmos para reproducir esta capacidad humana (desambiguar el significado) a menudo puede ser una  __[tarea muy difícil](https://es.wikipedia.org/wiki/Problema_no_resuelto)__. En la frase \"La carne está sabrosa\" hay también cierto contenido implícito: se asume que estamos hablando de carne cocida.\n",
    "\n",
    "**Referencias**\n",
    "\n",
    "__[Desambiguación lingüística](https://es.wikipedia.org/wiki/Desambiguaci%C3%B3n_ling%C3%BC%C3%ADstica)__\n",
    "\n",
    "\n",
    "Recursos lingüísticos\n",
    "\n",
    "__[WordNet](https://es.wikipedia.org/wiki/WordNet)__\n",
    "\n",
    "__[Spanish WordNet 3.0](http://timm.ujaen.es/recursos/spanish-wordnet-3-0/)__\n",
    "\n",
    "\n",
    "Estrategias \n",
    "\n",
    "__[Algoritmo Lesk](https://en.wikipedia.org/wiki/Lesk_algorithm)__\n",
    "\n",
    "__[Desambiguación del Sentido de las Palabras](http://dpinto.cs.buap.mx/pln/Autumn2010/wsd.pdf)__\n",
    "\n",
    "__[Estudio sobre métodos tipo Lesk usados para la desambiguación de sentidos de palabras](https://pdfs.semanticscholar.org/cd5f/5dd14c126325a81280407ddc2616f3704fca.pdf)__\n",
    "\n",
    "__[Supervised Word Sense Disambiguation: Facing Current Challenges](http://www.sepln.org/sites/default/files/monografia/archivos/2018-10/monografiaDavid.pdf)__\n",
    "\n",
    "###  Etiquetado gramatical (Part of Speech Tagging) **\n",
    "Como parte de la desambiguación, se suele realizar la tarea de asignar una categoría a cada palabra: sujeto, nombre, verbo, adjetivo. \n",
    "\n",
    "**Referencias**\n",
    "\n",
    "__[Etiquetado gramatical](https://es.wikipedia.org/wiki/Etiquetado_gramatical)__\n",
    "\n",
    "__[Using Wikicorpus & NLTK to build a Spanish part-of-speech tagger](https://www.cnts.ua.ac.be/pages/using-wikicorpus-nltk-to-build-a-spanish-part-of-speech-tagger)__\n",
    "\n",
    "__[Choosing a Spanish Part-of-Speech tagger for a lexically sensitive task](https://www.researchgate.net/publication/282828110_Choosing_a_Spanish_Part-of-Speech_tagger_for_a_lexically_sensitive_task)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoques\n",
    "Basado en reglas (sistemas expertos)\n",
    "Aprendizaje Automático (capturar patrones en datos históricos)\n",
    "\n",
    "Ejemplo: Detección de Spam, Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representaciones\n",
    "Dependiendo del tipo de problema NLP, el texto deberá transformarse en una representación adecuada para las herramientas y algoritmos empleandos para abordar el problema. Una de las más usadas es crear representaciones numéricas. Esencialmente, se trata de convertir texto en un vector/arreglo de números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectors\n",
    "\n",
    "Representaciones numéricas basados en conteos y frecuencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding (tuplas de palabras)\n",
    "Se crea un vocabulario con todas la palabras de todos los documentos. Y cada documento se representa como una arreglo donde se indica la presencia o ausencia de una palabra en el documento.\n",
    "![one-hot-encoding](one-hot-encoding.png)\n",
    "\n",
    "- Cada documento se representa con uno arreglo tan grande como todo el vocabulario! :(\n",
    "- Se pierde el órden y la frequencia de las palabras.\n",
    "- No captura relaciones entre palabras.\n",
    "- Su mayor ventaja es la simplicidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basadas en frecuencias\n",
    "**Conteos**\n",
    "\n",
    "El vector de cada documento contiene la cantidad de veces que aparece una palabra (no solo se marca su presencia/ausencia)\n",
    "\n",
    "**TF-IDF (Term frequency, inverse document frequency)**\n",
    "\n",
    "TF - La frecuencia de una palabra en un documento.\n",
    "IDF - Mientras en más documentos aparece menos significativa es la palabra en los documentos en las aparece.\n",
    "\n",
    "Captura la frequencia de las palabras en cada documento y en el contenido formado por el conjunto de los documentos.\n",
    "\n",
    "![tf-idf](tf-idf.png)\n",
    "\n",
    "El valor de TF-IDF para cada palabra aumenta por su frecuencia en un documento pero disminuye si al mismo tiempo aparece \n",
    "todo el conjunto de documentos (es un término común).\n",
    "\n",
    "La idea es capturar la importancia de las palabras en los documentos. No captura las relaciones entre las palabras.\n",
    "\n",
    "**Co-ocurrencias**\n",
    "\n",
    "Se representa con una matrix en la se indica el número de veces que dos palabras aparecen en la misma \"ventana\" de \n",
    "co-ocurrencia (nro de palabras a izquierda, derecha o ambos lados cercanas a otra).\n",
    "\n",
    "Trata de capturar la relaciones entre las palabras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "\n",
    "Asociación de palabras con códigos numéricos que capturan su similitud semánticas. Por ejemplo, Londres tendrá un valor numérico cercano a París porque ambas palabras tiene significado parecido (ambas son ciudades importantes de europa); de la misma manera, la distancia entre las palabras \"varón\" y \"mujer\" sería similar a la distancia que existe entre \"rey\" y \"reina\".\n",
    "\n",
    "Son generadas a partir de grandes cuerpos de texto por algoritmos basados en redes neuronales, reducción de la dimensionalidad de matrices de co-ocurrencia y modelos probabilísticos.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Word2vec\n",
    "\n",
    "https://github.com/aitoralmeida/spanish_word2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
