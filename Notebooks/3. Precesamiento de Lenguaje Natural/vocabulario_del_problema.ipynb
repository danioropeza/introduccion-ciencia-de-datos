{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Habilitar intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulario del problema\n",
    "En un proyecto de NLP se trabajan con colecciones de \"documentos\". Cada documento en un fragmento de texto que se debe procesar de manera individual (clasificar, representar, etc). Ejemplos de documentos: tweets, revisiones, artículos, libros, etc.\n",
    "\n",
    "El conjunto de todas la palabras que aparecen en todos los documentos constituye el vocabulario del problema. En muchos casos el tamaño del problema puede reducir el desempeño de la solución y es necesario reducirlo. En este notebook se muestra como realizar una de las tareas más comunes que ayudan a reducir el tamaño del vocabulario: la eliminación de palabras de parada (stop words).\n",
    "\n",
    "Los elementos en el vocabulario se conocen como \"tokens\"; dependiendo del problema y las decisiones de diseño podrian no ser necesariamente una palabra. (podrían ser emoticos, lemas o palabras compuestas, por ejemplo.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenización\n",
    "Es la primera tarea/proceso en cualquier proyecto NLP. Es fundamental realizarla bien para no afectar la calidad de los datos de entrada en las etapas siguientes. Se recomienda usar un tokenizer reconocido y evitar intentar programar uno desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenización de a nivel de oraciones.\n",
    "# https://www.lostiempos.com/deportes/multideportivo/20200115/olympic-albert-einstein-ucb-lpz-van-paso-firme-liga-superior\n",
    "texto = \"\"\"Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes. El ganador será representante de Bolivia en la Liga Sudamericana de Clubes 2020.\n",
    "\n",
    "El campeón defensor del título, Olympic, superó 3-0  a su verdugo de la final de la edición 2017, el también cochabambino San Simón. La victoria para las olympiquistas fue con sets de 25-14, 25-13 y 25-18.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.nltk.org/api/nltk.tokenize.html\n",
    "#Return a sentence-tokenized copy of text, using NLTK’s recommended sentence tokenizer \n",
    "#(currently PunktSentenceTokenizer for the specified language).\n",
    "#Descargar 'punkt' desde la consola (REPL) de python\n",
    "#>>> import nltk\n",
    "#>>> nltk.download('punkt')\n",
    "import nltk\n",
    "#from nltk.tokenize import sent_tokenize\n",
    "oraciones = nltk.tokenize.sent_tokenize(text=texto, language='spanish')\n",
    "len(oraciones)\n",
    "oraciones[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización de a nivel de palabras.\n",
    "La función nltk.word_tokenize(...) es el tokenizador a nivel de palabras recomendado por NLTK. Internamente usa una instancia de la clase TreebankWordTokenizer (en la versión más reciente)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Los',\n",
       " 'clubes',\n",
       " 'cochabambinos',\n",
       " 'de',\n",
       " 'Olympic',\n",
       " ',',\n",
       " 'Albert',\n",
       " 'Einstein',\n",
       " 'y',\n",
       " 'el',\n",
       " 'paceño',\n",
       " 'Universidad',\n",
       " 'Católica',\n",
       " 'Boliviana',\n",
       " '(',\n",
       " 'UCB',\n",
       " ')',\n",
       " 'avanzan',\n",
       " 'a',\n",
       " 'paso',\n",
       " 'firme',\n",
       " 'y',\n",
       " 'constante',\n",
       " 'rumbo',\n",
       " 'a',\n",
       " 'la',\n",
       " 'corona',\n",
       " 'en',\n",
       " 'la',\n",
       " 'Liga',\n",
       " 'Superior',\n",
       " 'de',\n",
       " 'voleibol',\n",
       " ',',\n",
       " 'rama',\n",
       " 'femenina',\n",
       " ',',\n",
       " 'que',\n",
       " 'se',\n",
       " 'desarrolla',\n",
       " 'en',\n",
       " 'el',\n",
       " 'coliseo',\n",
       " 'Julio',\n",
       " 'Borelli',\n",
       " 'Vitterito',\n",
       " 'de',\n",
       " 'La',\n",
       " 'Paz',\n",
       " ',',\n",
       " 'luego',\n",
       " 'de',\n",
       " 'cosechar',\n",
       " 'sendas',\n",
       " 'victorias',\n",
       " 'la',\n",
       " 'noche',\n",
       " 'de',\n",
       " 'este',\n",
       " 'martes',\n",
       " '.',\n",
       " 'El',\n",
       " 'ganador',\n",
       " 'será',\n",
       " 'representante',\n",
       " 'de',\n",
       " 'Bolivia',\n",
       " 'en',\n",
       " 'la',\n",
       " 'Liga',\n",
       " 'Sudamericana',\n",
       " 'de',\n",
       " 'Clubes',\n",
       " '2020',\n",
       " '.',\n",
       " 'El',\n",
       " 'campeón',\n",
       " 'defensor',\n",
       " 'del',\n",
       " 'título',\n",
       " ',',\n",
       " 'Olympic',\n",
       " ',',\n",
       " 'superó',\n",
       " '3-0',\n",
       " 'a',\n",
       " 'su',\n",
       " 'verdugo',\n",
       " 'de',\n",
       " 'la',\n",
       " 'final',\n",
       " 'de',\n",
       " 'la',\n",
       " 'edición',\n",
       " '2017',\n",
       " ',',\n",
       " 'el',\n",
       " 'también',\n",
       " 'cochabambino',\n",
       " 'San',\n",
       " 'Simón',\n",
       " '.',\n",
       " 'La',\n",
       " 'victoria',\n",
       " 'para',\n",
       " 'las',\n",
       " 'olympiquistas',\n",
       " 'fue',\n",
       " 'con',\n",
       " 'sets',\n",
       " 'de',\n",
       " '25-14',\n",
       " ',',\n",
       " '25-13',\n",
       " 'y',\n",
       " '25-18',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras = nltk.word_tokenize(texto)\n",
    "#type(palabras)\n",
    "palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Que', 'buena', 'pelicula', '.', 'Gracias', 'por', 'la', 'invitación', ':)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encuentre la diferencia :)\n",
    "nltk.tokenize.casual.casual_tokenize(\"Que buena pelicula. Gracias por la invitación :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Que',\n",
       " 'buena',\n",
       " 'pelicula',\n",
       " '.',\n",
       " 'Gracias',\n",
       " 'por',\n",
       " 'la',\n",
       " 'invitación',\n",
       " ':',\n",
       " ')']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"Que buena pelicula. Gracias por la invitación :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar palabras de parada\n",
    "\n",
    "Tener en cuenta que NO hay una lista universal y exhaustiva de estas palabras; cada  lenguage e incluso tipo de problema puede tener su propia lista de palabras de parada.\n",
    "\n",
    "Puesto que estas listas pueden variar dependiendo de la librería o incluso entre versiones de la misma librería, incluir este paso puede dificultar la reproducción de los resultados en otros entornos. Veremos más adelante que hay otros mecanismos para lidiar con este tipo de palabras (TF, IDF).\n",
    "\n",
    "Finalmente, quitar alguna palabra de parada como los artículos podría cambiar completamente el significado de algunas palabras compuestas. \"La Paz\" -> \"Paz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecutar en la consola REPL de python\n",
    "#>>> import nltk\n",
    "#>>> nltk.download('stopwords')\n",
    "nltk.corpus.stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#string.punctuation\n",
    "list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'algunas',\n",
       " 'algunos',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'como',\n",
       " 'con',\n",
       " 'contra',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'de',\n",
       " 'del',\n",
       " 'desde',\n",
       " 'donde',\n",
       " 'durante',\n",
       " 'e',\n",
       " 'el',\n",
       " 'ella',\n",
       " 'ellas',\n",
       " 'ellos',\n",
       " 'en',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'eras',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'esa',\n",
       " 'esas',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'esos',\n",
       " 'esta',\n",
       " 'estaba',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estabas',\n",
       " 'estad',\n",
       " 'estada',\n",
       " 'estadas',\n",
       " 'estado',\n",
       " 'estados',\n",
       " 'estamos',\n",
       " 'estando',\n",
       " 'estar',\n",
       " 'estaremos',\n",
       " 'estará',\n",
       " 'estarán',\n",
       " 'estarás',\n",
       " 'estaré',\n",
       " 'estaréis',\n",
       " 'estaría',\n",
       " 'estaríais',\n",
       " 'estaríamos',\n",
       " 'estarían',\n",
       " 'estarías',\n",
       " 'estas',\n",
       " 'este',\n",
       " 'estemos',\n",
       " 'esto',\n",
       " 'estos',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'estuviera',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuvieras',\n",
       " 'estuvieron',\n",
       " 'estuviese',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estuvieses',\n",
       " 'estuvimos',\n",
       " 'estuviste',\n",
       " 'estuvisteis',\n",
       " 'estuviéramos',\n",
       " 'estuviésemos',\n",
       " 'estuvo',\n",
       " 'está',\n",
       " 'estábamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'estás',\n",
       " 'esté',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estés',\n",
       " 'fue',\n",
       " 'fuera',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fueras',\n",
       " 'fueron',\n",
       " 'fuese',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'fueses',\n",
       " 'fui',\n",
       " 'fuimos',\n",
       " 'fuiste',\n",
       " 'fuisteis',\n",
       " 'fuéramos',\n",
       " 'fuésemos',\n",
       " 'ha',\n",
       " 'habida',\n",
       " 'habidas',\n",
       " 'habido',\n",
       " 'habidos',\n",
       " 'habiendo',\n",
       " 'habremos',\n",
       " 'habrá',\n",
       " 'habrán',\n",
       " 'habrás',\n",
       " 'habré',\n",
       " 'habréis',\n",
       " 'habría',\n",
       " 'habríais',\n",
       " 'habríamos',\n",
       " 'habrían',\n",
       " 'habrías',\n",
       " 'habéis',\n",
       " 'había',\n",
       " 'habíais',\n",
       " 'habíamos',\n",
       " 'habían',\n",
       " 'habías',\n",
       " 'han',\n",
       " 'has',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'haya',\n",
       " 'hayamos',\n",
       " 'hayan',\n",
       " 'hayas',\n",
       " 'hayáis',\n",
       " 'he',\n",
       " 'hemos',\n",
       " 'hube',\n",
       " 'hubiera',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubieras',\n",
       " 'hubieron',\n",
       " 'hubiese',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'hubieses',\n",
       " 'hubimos',\n",
       " 'hubiste',\n",
       " 'hubisteis',\n",
       " 'hubiéramos',\n",
       " 'hubiésemos',\n",
       " 'hubo',\n",
       " 'la',\n",
       " 'las',\n",
       " 'le',\n",
       " 'les',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'mucho',\n",
       " 'muchos',\n",
       " 'muy',\n",
       " 'más',\n",
       " 'mí',\n",
       " 'mía',\n",
       " 'mías',\n",
       " 'mío',\n",
       " 'míos',\n",
       " 'nada',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nosotras',\n",
       " 'nosotros',\n",
       " 'nuestra',\n",
       " 'nuestras',\n",
       " 'nuestro',\n",
       " 'nuestros',\n",
       " 'o',\n",
       " 'os',\n",
       " 'otra',\n",
       " 'otras',\n",
       " 'otro',\n",
       " 'otros',\n",
       " 'para',\n",
       " 'pero',\n",
       " 'poco',\n",
       " 'por',\n",
       " 'porque',\n",
       " 'que',\n",
       " 'quien',\n",
       " 'quienes',\n",
       " 'qué',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'seamos',\n",
       " 'sean',\n",
       " 'seas',\n",
       " 'sentid',\n",
       " 'sentida',\n",
       " 'sentidas',\n",
       " 'sentido',\n",
       " 'sentidos',\n",
       " 'seremos',\n",
       " 'será',\n",
       " 'serán',\n",
       " 'serás',\n",
       " 'seré',\n",
       " 'seréis',\n",
       " 'sería',\n",
       " 'seríais',\n",
       " 'seríamos',\n",
       " 'serían',\n",
       " 'serías',\n",
       " 'seáis',\n",
       " 'siente',\n",
       " 'sin',\n",
       " 'sintiendo',\n",
       " 'sobre',\n",
       " 'sois',\n",
       " 'somos',\n",
       " 'son',\n",
       " 'soy',\n",
       " 'su',\n",
       " 'sus',\n",
       " 'suya',\n",
       " 'suyas',\n",
       " 'suyo',\n",
       " 'suyos',\n",
       " 'sí',\n",
       " 'también',\n",
       " 'tanto',\n",
       " 'te',\n",
       " 'tendremos',\n",
       " 'tendrá',\n",
       " 'tendrán',\n",
       " 'tendrás',\n",
       " 'tendré',\n",
       " 'tendréis',\n",
       " 'tendría',\n",
       " 'tendríais',\n",
       " 'tendríamos',\n",
       " 'tendrían',\n",
       " 'tendrías',\n",
       " 'tened',\n",
       " 'tenemos',\n",
       " 'tenga',\n",
       " 'tengamos',\n",
       " 'tengan',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'tengáis',\n",
       " 'tenida',\n",
       " 'tenidas',\n",
       " 'tenido',\n",
       " 'tenidos',\n",
       " 'teniendo',\n",
       " 'tenéis',\n",
       " 'tenía',\n",
       " 'teníais',\n",
       " 'teníamos',\n",
       " 'tenían',\n",
       " 'tenías',\n",
       " 'ti',\n",
       " 'tiene',\n",
       " 'tienen',\n",
       " 'tienes',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'tuve',\n",
       " 'tuviera',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuvieras',\n",
       " 'tuvieron',\n",
       " 'tuviese',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'tuvieses',\n",
       " 'tuvimos',\n",
       " 'tuviste',\n",
       " 'tuvisteis',\n",
       " 'tuviéramos',\n",
       " 'tuviésemos',\n",
       " 'tuvo',\n",
       " 'tuya',\n",
       " 'tuyas',\n",
       " 'tuyo',\n",
       " 'tuyos',\n",
       " 'tú',\n",
       " 'un',\n",
       " 'una',\n",
       " 'uno',\n",
       " 'unos',\n",
       " 'vosotras',\n",
       " 'vosotros',\n",
       " 'vuestra',\n",
       " 'vuestras',\n",
       " 'vuestro',\n",
       " 'vuestros',\n",
       " 'y',\n",
       " 'ya',\n",
       " 'yo',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'él',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabrasParada = set( nltk.corpus.stopwords.words('spanish') + list(string.punctuation))\n",
    "palabrasParada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Los',\n",
       " 'clubes',\n",
       " 'cochabambinos',\n",
       " 'Olympic',\n",
       " 'Albert',\n",
       " 'Einstein',\n",
       " 'paceño',\n",
       " 'Universidad',\n",
       " 'Católica',\n",
       " 'Boliviana',\n",
       " 'UCB',\n",
       " 'avanzan',\n",
       " 'paso',\n",
       " 'firme',\n",
       " 'constante',\n",
       " 'rumbo',\n",
       " 'corona',\n",
       " 'Liga',\n",
       " 'Superior',\n",
       " 'voleibol',\n",
       " 'rama',\n",
       " 'femenina',\n",
       " 'desarrolla',\n",
       " 'coliseo',\n",
       " 'Julio',\n",
       " 'Borelli',\n",
       " 'Vitterito',\n",
       " 'La',\n",
       " 'Paz',\n",
       " 'luego',\n",
       " 'cosechar',\n",
       " 'sendas',\n",
       " 'victorias',\n",
       " 'noche',\n",
       " 'martes',\n",
       " 'El',\n",
       " 'ganador',\n",
       " 'representante',\n",
       " 'Bolivia',\n",
       " 'Liga',\n",
       " 'Sudamericana',\n",
       " 'Clubes',\n",
       " '2020',\n",
       " 'El',\n",
       " 'campeón',\n",
       " 'defensor',\n",
       " 'título',\n",
       " 'Olympic',\n",
       " 'superó',\n",
       " '3-0',\n",
       " 'verdugo',\n",
       " 'final',\n",
       " 'edición',\n",
       " '2017',\n",
       " 'cochabambino',\n",
       " 'San',\n",
       " 'Simón',\n",
       " 'La',\n",
       " 'victoria',\n",
       " 'olympiquistas',\n",
       " 'sets',\n",
       " '25-14',\n",
       " '25-13',\n",
       " '25-18']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabrasSinPalabrasDeParada = [palabra for palabra in palabras if palabra not in palabrasParada]\n",
    "palabrasSinPalabrasDeParada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otras tareas de limpieza que se pueden considerar\n",
    "\n",
    "- Unificar el case - string.lower().\n",
    "- Quitar acentos? probablemente no es buena idea si el contenido está en castellano\n",
    "- Procesar contracciones? I'm -> I am \n",
    "- Quitar caracteres expeciales - #@!\n",
    "- Quitar markup - Ej contenido HTML\n",
    "- Corregir texto -typos, noooo por favoooorrr\n",
    "\n",
    "http://norvig.com/spell-correct.html\n",
    "\n",
    "https://github.com/fsondej/autocorrect\n",
    "\n",
    "https://github.com/MajorTal/DeepSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
